{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from auxiliary import *\n",
        "\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Self-selection, heterogeneity, and causal graphs\n",
        "\n",
        "**Overview**\n",
        "\n",
        "* Introduction\n",
        "\n",
        "* Nonignorability and selection on the unobservables revisited\n",
        "\n",
        "* Selection on the unobservables and the utility of additional posttreatment measures of the outcome\n",
        "\n",
        "* Causal graphs for complex patterns of self-selection and heterogeneity\n",
        "\n",
        "* Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "**Alternatives to back-door identification**\n",
        "\n",
        "The next chapters deal with:\n",
        "\n",
        "* instrumental variables\n",
        "* front-door identification with causal mechanisms\n",
        "* conditioning estimators using pretreatment variables\n",
        "\n",
        "Why do we need to consider alternatives?\n",
        "\n",
        "$\\rightarrow$selection on unobservables / nonignorability of treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "What makes an unobservable?\n",
        "\n",
        "* simple confounding, stable unobserved common cause of treatment and outcome variable\n",
        "\n",
        "* subtle confounding, direct self-selection into the treatment based on accurate perceptions of \n",
        "the individual level treatment effect\n",
        "\n",
        "Selection on unobservables as a combination of two features:\n",
        "\n",
        "* treatment effect heterogeneity\n",
        "* self-selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Nonignorability and selection on the unobservables\n",
        "\n",
        "### Selection on observables \n",
        "\n",
        "\u003cimg src\u003d\"material/figure-4-8.png\" height\u003d500 width\u003d500 /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Selection on unobservables\n",
        "\n",
        "\u003cimg src\u003d\"material/figure-4-9.png\" height\u003d500 width\u003d500 /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Selection on the unobservables and the utility of additional posttreatment measures of the outcome\n",
        "\n",
        "**Catholic school example**\n",
        "\n",
        "* claim that Catholic schools are more effective than public schools in teaching mathematics and \n",
        "reading to equivalent High School students.\n",
        "\n",
        "* conditioning on family background and motivation to learn \n",
        "\n",
        "* those enrolling into Catholic school have the most to gain from doing so"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": "**Notation**\n\n* $Y_{10}$, observed score on standardized achievement test given in tenth grade\n\n* $D$ causal variable taking value one if student attends Catholic school\n\n* $U$ unobserved motivation to learn, differences in home environment, anticipation of causal \neffect itself\n\n\nWe proceed in two steps:\n\n* assess identification for given directed graphs\n\n* examine structure of directed graph itself\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "\n",
        "\u003cimg src\u003d\"material/figure-8-1.png\" height\u003d500 width\u003d500 /\u003e\n",
        "\n",
        "We cannot identify the causal effect of $D$ on $Y_{10}$ in subfigure (a) but in subfigure (b).\n",
        "However, at what cost?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "$Y_{10}$ does not satisfy the Condition 2 of the back-door criterion. As such, it adjusts away \n",
        "some of the total causal effect of $D$ on $Y_{12}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "Let $E$ denote an student\u0027s ability for test taking. Then maybe this is a more complete picture?\n",
        "\n",
        "\u003cimg src\u003d\"material/figure-8-2.png\" height\u003d500 width\u003d500 /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "Back-door adjustment by $Y_{10}$ ineffective again after revisiting economic implications of the \n",
        "imposed graph. In fact, $Y_{10}$ is now a collider variable that induces a noncausal dependence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Panel Data Demonstration\n",
        "\n",
        "The motivation behind this example is simply to show that we cannot learn anything about the \n",
        "underlying causal effect with the conventional strategies and how we model self-selection in the \n",
        "data generating process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [],
      "source": [
        "def get_propensity_score(o, u):\n",
        "    \"\"\"Get the propensity score.\"\"\"\n",
        "    level \u003d -3.8 + o + u \n",
        "    return np.exp(level) / (1 + np.exp(level))\n",
        "\n",
        "\n",
        "def get_treatment_status(o, u):\n",
        "    \"\"\"Sampling treatment status\"\"\"\n",
        "    # Following the causal graph, the treatment indicator is only a function \n",
        "    # of the background characteristics O and the unobservable U.\n",
        "    p \u003d get_propensity_score(o, u)\n",
        "    return np.random.choice([1, 0], p\u003d[p, 1 - p])\n",
        "   \n",
        "def get_covariates():\n",
        "    \"\"\" Get covariates.\"\"\"\n",
        "    o, e \u003d np.random.normal(size\u003d2)\n",
        "    x, u \u003d o + np.random.normal(size\u003d2)    \n",
        "    return o, u, x, e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [],
      "source": "def get_potential_outcomes(grade, o, x, e, u, scenario\u003d0, selection\u003dFalse):\n    \"\"\"Get potential outcomes.\n    \n    Sampling of potential outcome of an individual for the panel data demonstration.\n    \n    Args:\n        grade: an integer for the grade the individual is in.\n        o, x, e : floats of observable characteristics.\n        u: a float of unobservable characteristic.\n        scenario: an integer for the scenario: (0) no role for E, (1) role for E.\n        selection: a boolean indicating whether there is selection on unobservables.\n    \n    Returns:\n        A tuple of potential outcomes (Y_0, Y_1).\n    \n    \"\"\"\n    # We want to make sure we only pass in valid input.\n    assert scenario in range(2)\n    assert selection in [True, False]\n    assert grade in [10, 11, 12]\n    \n    # There is a natural progression in test scores.\n    level \u003d dict()\n    level[10] \u003d 100\n    level[11] \u003d 101\n    level[12] \u003d 102\n        \n    if scenario \u003d\u003d 0:\n        y_0 \u003d level[grade] + o + u + x + np.random.normal()\n    elif scenario \u003d\u003d 1:\n        y_0 \u003d level[grade] + o + u + x + e + np.random.normal()\n    else:\n        raise NotImplementedError\n    \n    # Sampling of treatment effects. The key difference for selection on unobservables is in how \n    # the overall treatment effect depends on the  unobservable U that also affects the choice \n    # probability. This was the major criticism of Coleman\u0027s work.\n    delta_1 \u003d np.random.normal(loc\u003d10, scale\u003d1)\n    if selection:\n        delta_2 \u003d np.random.normal(loc\u003du)\n    else:\n        delta_2 \u003d np.random.normal()\n    \n    if grade \u003d\u003d 10:\n        y_1 \u003d y_0 + delta_1 + delta_2\n    elif grade \u003d\u003d 11:\n        y_1 \u003d y_0 + (1 + delta_1) + delta_2\n    elif grade \u003d\u003d 12:\n        y_1 \u003d y_0 + (2 + delta_1) + delta_2\n        \n    return y_0, y_1"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [],
      "source": [
        "def get_sample_panel_demonstration(num_agents\u003d1000, scenario\u003d0, selection\u003dFalse, seed\u003d123):\n",
        "    \"\"\"Get sample for demonstration.\n",
        "    \n",
        "    Create a random sample for the demonstration of the usefulness of (or lack thereof) of having\n",
        "    additional posttreatment measures of the outcome.\n",
        "    \n",
        "    Args:\n",
        "        num_agents: an integer for the number of agents in the sample\n",
        "        scenario: an integer that indicates whether to include E as a determinant of test scores\n",
        "        selection: a boolean variable indicating whether selection on unobservables is an issue\n",
        "        seed: an integer setting the random seed\n",
        "        \n",
        "    Returns:\n",
        "        A dataframe with the simulated sample.\n",
        "    \n",
        "    \"\"\"\n",
        "    # We first initialize an empty DataFrame that holds the information for each individual\n",
        "    # and each time period.\n",
        "    columns \u003d [\u0027Y\u0027, \u0027D\u0027, \u0027O\u0027,\u0027X\u0027, \u0027E\u0027, \u0027U\u0027, \u0027Y_1\u0027, \u0027Y_0\u0027]\n",
        "    index \u003d list()\n",
        "    for i in range(num_agents):\n",
        "        for j in [10, 11, 12]:\n",
        "            index.append((i, j))\n",
        "    index \u003d pd.MultiIndex.from_tuples(index, names\u003d(\u0027Identifier\u0027, \u0027Grade\u0027))\n",
        "    df \u003d pd.DataFrame(columns\u003dcolumns, index\u003dindex)\n",
        "\n",
        "    # Now we are ready to simulate the sample with the desired characteristics.\n",
        "    np.random.seed(seed)\n",
        "    for i in range(num_agents):\n",
        "\n",
        "        o, u, x, e \u003d get_covariates()\n",
        "        d \u003d get_treatment_status(o, u)\n",
        "        for grade in [10, 11, 12]:\n",
        "            y_0, y_1 \u003d get_potential_outcomes(grade, o, u, x, e, scenario, selection)\n",
        "            y \u003d d * y_1 + (1 - d) * y_0\n",
        "            df.loc[(i, grade), :] \u003d [y, d, o, x, e, u, y_1, y_0]\n",
        "    \n",
        "    # Finally some type definitions for pretty output.\n",
        "    df \u003d df.astype(np.float)\n",
        "    df \u003d df.astype({\u0027D\u0027: np.int})\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style\u003d\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003eY\u003c/th\u003e\n",
              "      \u003cth\u003eD\u003c/th\u003e\n",
              "      \u003cth\u003eO\u003c/th\u003e\n",
              "      \u003cth\u003eX\u003c/th\u003e\n",
              "      \u003cth\u003eE\u003c/th\u003e\n",
              "      \u003cth\u003eU\u003c/th\u003e\n",
              "      \u003cth\u003eY_1\u003c/th\u003e\n",
              "      \u003cth\u003eY_0\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003eIdentifier\u003c/th\u003e\n",
              "      \u003cth\u003eGrade\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth rowspan\u003d\"3\" valign\u003d\"top\"\u003e0\u003c/th\u003e\n",
              "      \u003cth\u003e10\u003c/th\u003e\n",
              "      \u003ctd\u003e97.641896\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e-1.085631\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.802652\u003c/td\u003e\n",
              "      \u003ctd\u003e0.997345\u003c/td\u003e\n",
              "      \u003ctd\u003e-2.591925\u003c/td\u003e\n",
              "      \u003ctd\u003e107.386177\u003c/td\u003e\n",
              "      \u003ctd\u003e97.641896\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e11\u003c/th\u003e\n",
              "      \u003ctd\u003e100.299138\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e-1.085631\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.802652\u003c/td\u003e\n",
              "      \u003ctd\u003e0.997345\u003c/td\u003e\n",
              "      \u003ctd\u003e-2.591925\u003c/td\u003e\n",
              "      \u003ctd\u003e108.565873\u003c/td\u003e\n",
              "      \u003ctd\u003e100.299138\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e12\u003c/th\u003e\n",
              "      \u003ctd\u003e98.872349\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e-1.085631\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.802652\u003c/td\u003e\n",
              "      \u003ctd\u003e0.997345\u003c/td\u003e\n",
              "      \u003ctd\u003e-2.591925\u003c/td\u003e\n",
              "      \u003ctd\u003e112.397378\u003c/td\u003e\n",
              "      \u003ctd\u003e98.872349\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth rowspan\u003d\"2\" valign\u003d\"top\"\u003e1\u003c/th\u003e\n",
              "      \u003cth\u003e10\u003c/th\u003e\n",
              "      \u003ctd\u003e96.817222\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.619191\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.042445\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.769433\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.492665\u003c/td\u003e\n",
              "      \u003ctd\u003e108.207462\u003c/td\u003e\n",
              "      \u003ctd\u003e96.817222\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e11\u003c/th\u003e\n",
              "      \u003ctd\u003e99.856079\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.619191\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.042445\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.769433\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.492665\u003c/td\u003e\n",
              "      \u003ctd\u003e111.410977\u003c/td\u003e\n",
              "      \u003ctd\u003e99.856079\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "                           Y  D         O         X         E         U  \\\n",
              "Identifier Grade                                                          \n",
              "0          10      97.641896  0 -1.085631 -0.802652  0.997345 -2.591925   \n",
              "           11     100.299138  0 -1.085631 -0.802652  0.997345 -2.591925   \n",
              "           12      98.872349  0 -1.085631 -0.802652  0.997345 -2.591925   \n",
              "1          10      96.817222  0 -0.619191 -0.042445 -0.769433 -0.492665   \n",
              "           11      99.856079  0 -0.619191 -0.042445 -0.769433 -0.492665   \n",
              "\n",
              "                         Y_1         Y_0  \n",
              "Identifier Grade                          \n",
              "0          10     107.386177   97.641896  \n",
              "           11     108.565873  100.299138  \n",
              "           12     112.397378   98.872349  \n",
              "1          10     108.207462   96.817222  \n",
              "           11     111.410977   99.856079  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_agents, scenario, selection \u003d 1000, 0, False\n",
        "df \u003d get_sample_panel_demonstration(num_agents, scenario, selection)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "What is the average treatment effect and how does it depend on the presence of selection?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "-"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Selection False\n",
            " Grade 10:  ATE 10.090\n",
            " Grade 12:  ATE 12.014\n",
            "\n",
            "\n",
            " Selection True\n",
            " Grade 10:  ATE 10.100\n",
            " Grade 12:  ATE 12.023\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_agents, scenario \u003d 1000, 0\n",
        "\n",
        "# This setup allows to freeze some arguments of the function\n",
        "# that do not change during the analysis.\n",
        "from functools import partial\n",
        "simulate_sample \u003d partial(get_sample_panel_demonstration, num_agents, scenario)\n",
        "\n",
        "for selection in [False, True]:\n",
        "    print(\u0027 Selection {:}\u0027.format(selection))\n",
        "    df \u003d simulate_sample(selection)\n",
        "    for grade in [10, 12]:\n",
        "        subset \u003d df.loc[(slice(None), grade), :]\n",
        "        stat \u003d (subset[\u0027Y_1\u0027] - subset[\u0027Y_0\u0027]).mean()\n",
        "        print(\" Grade {:}:  ATE {:5.3f}\".format(*[grade, stat]))\n",
        "    print(\u0027\\n\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "The average treatment effects are unaffected by selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "-"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Selection False\n",
            " Grade 10:  ATT 10.012   ATC 10.098\n",
            " Grade 12:  ATT 12.134   ATC 12.001\n",
            "\n",
            "\n",
            " Selection True\n",
            " Grade 10:  ATT 9.894   ATC 10.121\n",
            " Grade 12:  ATT 12.016   ATC 12.024\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for selection in [False, True]:\n",
        "    print(\u0027 Selection {:}\u0027.format(selection))\n",
        "    df \u003d simulate_sample(selection)\n",
        "    for grade in [10, 12]:\n",
        "        subset \u003d df.loc[(slice(None), grade), :]\n",
        "            \n",
        "        treated \u003d subset[\u0027D\u0027] \u003d\u003d 1\n",
        "        control \u003d subset[\u0027D\u0027] \u003d\u003d 0\n",
        "\n",
        "        stat \u003d list()\n",
        "        stat.append((subset[\u0027Y_1\u0027][treated] - subset[\u0027Y_0\u0027][treated]).mean())\n",
        "        stat.append((subset[\u0027Y_1\u0027][control] - subset[\u0027Y_0\u0027][control]).mean())\n",
        "        print(\" Grade {:}:  ATT {:5.3f}   ATC {:5.3f}\".format(grade, *stat))\n",
        "    print(\u0027\\n\u0027)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grade: 10  Model: Y ~ D\n",
            "   Estimated Treatment Effect: 12.650\n",
            "\n",
            "Grade: 10  Model: Y ~ D + X + O\n",
            "   Estimated Treatment Effect: 10.315\n",
            "\n",
            "Grade: 12  Model: Y ~ D\n",
            "   Estimated Treatment Effect: 14.731\n",
            "\n",
            "Grade: 12  Model: Y ~ D + X + O\n",
            "   Estimated Treatment Effect: 12.466\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for grade in [10, 12]:\n",
        "    for model in [\u0027Y ~ D\u0027, \u0027Y ~ D + X + O\u0027]:\n",
        "        subset \u003d df.loc[(slice(None), grade), :]\n",
        "        rslt \u003d smf.ols(formula\u003dmodel, data\u003dsubset).fit()\n",
        "        stat \u003d rslt.params[\u0027D\u0027]\n",
        "        print(\u0027Grade: {}  Model: {:}\u0027.format(*[grade, model]))\n",
        "        print(\u0027   Estimated Treatment Effect: {:5.3f}\\n\u0027.format(stat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "None of the estimates come even close to our parameters of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Causal graphs for complex patterns of self-selection\n",
        "\n",
        "We want to make sure that complex patterns of self-selection can be represented by directed graphs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": "### Separate graphs for separate latent classes\n\n**Groups**\n\n* $G\u003d1$, selection of schools mainly for lifestyle reasons, proximity to home and taste for \nschool cultures\n\n* $G\u003d2$, selection of schools to maximize expected achievement"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "\u003cimg src\u003d\"material/figure-8-3.png\" height\u003d500 width\u003d500 /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "\n",
        "What are the economic mechanisms are represented by each of the arrows? Why would we expect them \n",
        "to differ across the two groups?\n",
        "\n",
        "* families of the second group are more likely to send their children to charter schools $d_2 \u003e d_1$\n",
        "\n",
        "* parents with higher levels of education are more likely to send their children to charter  schools\n",
        " as they value distinctive forms of education $\\alpha_1, \\alpha_2 \u003e 0$ and are able to support \n",
        " their children with their homework $\\beta_1, \\beta_2 \u003e 0$.\n",
        "\n",
        "* existing research suggests $\\delta_1, \\delta_2 \u003e 0$ and $\\delta_2 \u003e \\delta_1$ as families in \n",
        "second group put more effort in matching their children to schools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "What happens if we block the back-door path by conditioning in $P$ but ignore the existence of \n",
        "two latent classes? If $P$ is associated with latent class membership, then we do not properly \n",
        "weigh the stratum-specific treatment effects as there is heterogeneity within strata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### A single graph that represents all latent classes\n",
        "\n",
        "\u003cimg src\u003d\"material/figure-8-4.png\" height\u003d500 width\u003d500 /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "\u003cimg src\u003d\"material/figure-8-5.png\" height\u003d500 width\u003d500 /\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Self-selection into the latent class\n",
        "\n",
        "\u003cimg src\u003d\"material/figure-8-6.png\" height\u003d500 width\u003d500 /\u003e"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}