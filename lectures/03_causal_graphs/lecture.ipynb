{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Causal graphs\n",
    "\n",
    "\n",
    "Graph notation less general than potential outcome framework, but \n",
    "\n",
    "* thinking about causal systems\n",
    "* uncover identification strategies\n",
    "\n",
    "> It is useful to separate the inferential problem into statistical and identification components. Studies of identification seek to characterize the conclusions sthat could be drawsn if one could use the sampling process to obtain an unlimited number of observations. (Manski, 1995)\n",
    "\n",
    "The two most crucial ingredients for an identification analysis are:\n",
    "\n",
    "* The set of assumptions about causal relationships that the analysis is willing to assert based on theory and past research, including assumptions about relationships between variables that have not been observed but that are related both to the cause and outcome of interest.\n",
    "\n",
    "* The pattern of informatin one can assume would be contained in the joint distribution of the variables in the observed dataset if all memebers of the population had been included in the sample that generated the dataset.\n",
    "\n",
    "$\\rightarrow$ causal graphs offer an effective and efficient representation for both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic elements of causal graphs\n",
    "\n",
    "* nodes\n",
    "* edges\n",
    "* paths\n",
    "    * parent and child\n",
    "    * decendent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"material/graph_with_cycle.png\" height=\"200\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two representations of the joint depdendence of $A$ and $B$ on an unobserved common cause.\n",
    "\n",
    "<img src=\"material/graph_shorthand_unobserved_common_cause.png\" height=\"500\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at some basic patterns that will turn out to appear frequently.\n",
    "\n",
    "* chain of mediation\n",
    "* fork of mutual causation\n",
    "\n",
    "$\\rightarrow$ unconditional association\n",
    "\n",
    "* fork of mutual dependence, **collider variable**\n",
    "\n",
    "$\\rightarrow$ no unconditional association, but conditionnal on **collider variable**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"material/basic_causal_relationships.png\" height=\"200\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditioning and confounding\n",
    "\n",
    "<img src=\"material/confounding_variable.png\" height=\"500\" width=500 />\n",
    "\n",
    "* $C$ is a **confounding variable** that affects both the dependent and independent variable.\n",
    "\n",
    "* Conditioning is a modelig strategy that allows to determine causal effects in the presence of observed confounders.\n",
    "\n",
    "$\\rightarrow$ What happens if $C$ is unobserved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How about an example from educational choice where we have observed and unobserved confounders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"material/fig-confounders-education.png\" height=500 width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graphs and structural equations\n",
    "\n",
    "Let's look at another example and assume we are interested in the effect of parental background (P), charter schools (D), and neighborhoods (N) on test scores (Y).\n",
    "\n",
    "We could set up the following **linear** regression equations:\n",
    "\n",
    "\\begin{align*}\n",
    "D & = \\alpha_D + b_P P + \\epsilon_D \\\\\n",
    "Y & = \\alpha_Y + b_D D + b_P P + + b_N N + \\epsilon_Y\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"material/fig-equivalent-representations-standard.png\" height=500 width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"material/fig-equivalent-representations-magnified.png\" height=500 width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set up the same *nonparametric* structural equations for both representations:\n",
    "\n",
    "\\begin{align*}\n",
    "P & = f_P(\\epsilon_1)    \\\\\n",
    "N & = f_N(\\epsilon_3) \\\\\n",
    "D & = f_D(P, \\epsilon_2) \\\\\n",
    "Y & = f_Y(P, D, N, \\epsilon_4)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to simulate a sample from a set of structural equations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>P</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990626</td>\n",
       "      <td>3.186022</td>\n",
       "      <td>0.762263</td>\n",
       "      <td>0.354792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552768</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.040949</td>\n",
       "      <td>0.494129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.670591</td>\n",
       "      <td>1.096380</td>\n",
       "      <td>0.413915</td>\n",
       "      <td>0.419244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.022789</td>\n",
       "      <td>1.122093</td>\n",
       "      <td>0.908745</td>\n",
       "      <td>0.865778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.708393</td>\n",
       "      <td>3.449747</td>\n",
       "      <td>0.897842</td>\n",
       "      <td>0.200958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y         D         P         N\n",
       "0  0.990626  3.186022  0.762263  0.354792\n",
       "1  0.552768  0.012214  0.040949  0.494129\n",
       "2  0.670591  1.096380  0.413915  0.419244\n",
       "3  3.022789  1.122093  0.908745  0.865778\n",
       "4  0.708393  3.449747  0.897842  0.200958"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parametrization of linear equations\n",
    "alpha_D = 1\n",
    "alpha_Y = 1\n",
    "\n",
    "beta_P = 0.8\n",
    "beta_N = 0.7\n",
    "beta_D = -0.3\n",
    "\n",
    "# distributional assumptions\n",
    "get_unobservable = np.random.normal\n",
    "get_observable = np.random.uniform\n",
    "\n",
    "num_agents = 10000\n",
    "data = np.tile(np.nan, (num_agents, 4))\n",
    "for i in range(num_agents):\n",
    "    P = get_observable()\n",
    "    N = get_observable()\n",
    "    D = alpha_D + beta_P * P + get_unobservable()\n",
    "    Y = alpha_Y + beta_D * D + beta_P * P + beta_N * N + get_unobservable()\n",
    "    data[i, :] = [Y, D, P, N]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Y', 'D', 'P', 'N'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let\"s see if we can uncover the structural parameters by a simple ordinary-least-squares regression and thus go full circle from a parametric structural equation model to a causal graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.134</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.134</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   516.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 14 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>2.66e-312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:24:30</td>     <th>  Log-Likelihood:    </th> <td> -14148.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>2.830e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9996</td>      <th>  BIC:               </th> <td>2.833e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.0257</td> <td>    0.028</td> <td>   36.506</td> <td> 0.000</td> <td>    0.971</td> <td>    1.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D</th>         <td>   -0.3066</td> <td>    0.010</td> <td>  -30.571</td> <td> 0.000</td> <td>   -0.326</td> <td>   -0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P</th>         <td>    0.7658</td> <td>    0.036</td> <td>   21.462</td> <td> 0.000</td> <td>    0.696</td> <td>    0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>N</th>         <td>    0.7098</td> <td>    0.035</td> <td>   20.540</td> <td> 0.000</td> <td>    0.642</td> <td>    0.778</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.752</td> <th>  Durbin-Watson:     </th> <td>   2.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.417</td> <th>  Jarque-Bera (JB):  </th> <td>   1.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.031</td> <th>  Prob(JB):          </th> <td>   0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.982</td> <th>  Cond. No.          </th> <td>    8.75</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.134\n",
       "Model:                            OLS   Adj. R-squared:                  0.134\n",
       "Method:                 Least Squares   F-statistic:                     516.9\n",
       "Date:                Sun, 14 Apr 2019   Prob (F-statistic):          2.66e-312\n",
       "Time:                        17:24:30   Log-Likelihood:                -14148.\n",
       "No. Observations:               10000   AIC:                         2.830e+04\n",
       "Df Residuals:                    9996   BIC:                         2.833e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.0257      0.028     36.506      0.000       0.971       1.081\n",
       "D             -0.3066      0.010    -30.571      0.000      -0.326      -0.287\n",
       "P              0.7658      0.036     21.462      0.000       0.696       0.836\n",
       "N              0.7098      0.035     20.540      0.000       0.642       0.778\n",
       "==============================================================================\n",
       "Omnibus:                        1.752   Durbin-Watson:                   2.024\n",
       "Prob(Omnibus):                  0.417   Jarque-Bera (JB):                1.773\n",
       "Skew:                           0.031   Prob(JB):                        0.412\n",
       "Kurtosis:                       2.982   Cond. No.                         8.75\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "y, x = dmatrices('Y ~ D + P + N', data = df)\n",
    "model_spec = sm.OLS(y, x)\n",
    "model_spec.fit().summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
